---
layout: post
title: "Me tl;dr-ing:: Summarizing using LLMS is good when volume is a good predictor of importance which isn't often the case. Still true in 2025?  May 2024:: Gerben Wierda::: When ChatGPT summarises, it actually does nothing of the kind. – R&amp;A IT Strategy &amp; Architecture"
---
[Discovered](http://rolandtanglao.com/2020/07/29/p1-blogthis-checkvist-list-links-to-blog/): Feb 9, 2025 07:48 [Me tl;dr-ing:: Summarizing using LLMS is good when volume is a good predictor of importance which isn't often the case. Still true in 2025?  May 2024:: Gerben Wierda::: When ChatGPT summarises, it actually does nothing of the kind. – R&amp;A IT Strategy &amp; Architecture](https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/)

## QUOTE:

* Read the whole thing: [When ChatGPT summarises, it actually does nothing of the kind. – R&amp;A IT Strategy &amp; Architecture](https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/)

>So, when will shortening the text be good enough for a reliable summary? Probably only when summarising consists of nothing else than turning something unnecessarily repetitive and long-winding into something short, i.e. when volume is a good predictor of importance. That is far less of a use case than people think. In the meantime, the result itself will — errors and all — suggest to readers that it is a true and reliable summary and we’re not going to doubt that, human as we are.

## Previously

* January 30, 2025: [David Crawshaw's sketch.dev LLM hello world gets into a loop about deleting duplicate files](https://rolandtanglao.com/2025/01/30/p0814-a5ph-sketch-dev-llm-software-dev-david-crawshaw/)
