---
layout: post
title: "ME: tl;dr-ing: Since the days of the analog world-wide telephone system and probably long before that :-) we have had systems that nobody knows how the whole thing works;  Lorin Hochstein:: Nobody knows how the whole system works – Surfing Complexity"
---
[Discovered](http://rolandtanglao.com/2020/07/29/p1-blogthis-checkvist-list-links-to-blog/): Feb 9, 2026 05:27 (UTC) [ME: tl;dr-ing: Since the days of the analog world-wide telephone system and probably long before that :-) we have had systems that nobody knows how the whole thing works;  Lorin Hochstein:: Nobody knows how the whole system works – Surfing Complexity](https://surfingcomplexity.blog/2026/02/08/nobody-knows-how-the-whole-system-works/)

## QUOTE:

* Read the whole thing: [Lorin Hochstein:: Nobody knows how the whole system works – Surfing Complexity](https://surfingcomplexity.blog/2026/02/08/nobody-knows-how-the-whole-system-works/)

>In their own ways, Wardley, Jacob, Perens, and Bucciarelli are all correct.

>Wardley’s right that it’s dangerous to build things where we don’t understand the underlying mechanism of how they actually work. This is precisely why magic is used as an epithet in our industry. Magic refers to frameworks that deliberately obscure the underlying mechanisms in service of making it easier to build within that framework. Ruby on Rails is the canonical example of a framework that uses magic.

>Jacob is right that AI is changing the way that normal software development work gets done. It’s a new capability that has proven itself to be so useful that it clearly isn’t going away. Yes, it represents a significant shift in how we build software, it moves us further away from how the underlying stuff actually works, but the benefits exceed the risks.

>Perens is right that the scenario that Wardley fears has, in some sense, already come to pass. Modern CPU architectures and operating systems contain significant complexity, and many software developers are blissfully unaware of how these things really work. Yes, they have mental models of how the system below them works, but those mental models are incorrect in fundamental ways.

>Finally, Bucciarelli is right that systems like telephony are so inherently complex, have been built on top of so many different layers in so many different places, that no one person can ever actually understand how the whole thing works. This is the fundamental nature of complex technologies: our knowledge of these systems will always be partial, at best. Yes, AI will make this situation worse. But it’s a situation that we’ve been in for a long time.
