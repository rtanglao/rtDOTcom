I"Ú<ul>
  <li><code class="language-plaintext highlighter-rouge">â€œOn the Dangers of Stochastic Parrotsâ€ is not a write-up of original research. Itâ€™s a synthesis of LLM critiques that Bender and others have made: of the biases encoded in the models; the near impossibility of studying whatâ€™s in the training data, given the fact they can contain billions of words; the costs to the climate; the problems with building technology that freezes language in time and thus locks in the problems of the past.</code> <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">Please read the whole thing</a></li>
  <li>Judith Butler, UC Berkley: â€œOr that human potential â€” thatâ€™s the fascist idea â€” human potential is more fully actualized with AI than without itâ€. <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">AGAIN :-), please read the whole thing</a></li>
  <li></li>
</ul>

<h3 id="previously">Previously</h3>

<ul>
  <li>January 9, 2020:  <a href="http://rolandtanglao.com/2020/01/19/p1-canosp-firefox-support-question-tagging-project-machine-learning-university-alberta/">Working with 4 University of Alberta Computer Science Students in the CANOSP program on a machine learning project to auto-tag Firefox desktop support questions based on a human trained dataset</a> &lt;- in retrospect this seems like a primitive project now :-) Is this better with GPT-3 or 4?</li>
</ul>
:ET