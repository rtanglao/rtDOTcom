I"<ul>
  <li>
    <p><a href="http://rolandtanglao.com/2020/07/29/p1-blogthis-checkvist-list-links-to-blog/">Discovered</a> Jan 17, 2021. <a href="https://thesephist.com/posts/ai/">The long future of artificial intelligence</a> “Firing up a multi-million dollar server farm to train a cutting-edge natural language model like GPT-3 feels a lot like firing up a building-sized computer in the early days of classical computing. We didn’t get to smartphones by simply shrinking vacuum tubes and punchcards; we got here because we found new substrates for the same computational power, namely laser-etched transistors on silicon. I imagine, in a hundred years, if we have GPT-10 in our pockets, it won’t run on GPUs and TPUs, but a new material entirely.</p>

    <p>I believe there exist materials that will enable smaller, faster, far cheaper and far more efficient computers that can see, think, and speak” &lt;– <a href="http://rolandtanglao.com/2021/01/14/p1-climbing-towards-natural-language-understanding-NLU-meaning-form-age-of-data/">I don’t think GPT-3 is intelligent see Climbing towards NLU:On Meaning, Form, and Understanding in the Age of Data</a> but perhaps on different sorts of computers will get closer or achieve an “intelligence” breakthrough and Linus aka <a href="https://twitter.com/thesephist">@thesephist</a>  is right when he writes “Inventing the computer and the deep neural network may still be one of the first few steps in replicating the magic of the enchanted loom” ?!?</p>
  </li>
</ul>

:ET