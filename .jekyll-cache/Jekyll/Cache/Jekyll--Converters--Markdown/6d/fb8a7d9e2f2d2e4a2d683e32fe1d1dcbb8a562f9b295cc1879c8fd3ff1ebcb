I"C<p><a href="http://rolandtanglao.com/2020/07/29/p1-blogthis-checkvist-list-links-to-blog/">Discovered</a>: Feb 9, 2025 07:48 <a href="https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/">Me tl;dr-ing:: Summarizing using LLMS is good when volume is a good predictor of importance which isn’t often the case. Still true in 2025?  May 2024:: Gerben Wierda::: When ChatGPT summarises, it actually does nothing of the kind. – R&amp;A IT Strategy &amp; Architecture</a></p>

<h2 id="quote">QUOTE:</h2>

<ul>
  <li>Read the whole thing: <a href="https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/">When ChatGPT summarises, it actually does nothing of the kind. – R&amp;A IT Strategy &amp; Architecture</a></li>
</ul>

<blockquote>
  <p>So, when will shortening the text be good enough for a reliable summary? Probably only when summarising consists of nothing else than turning something unnecessarily repetitive and long-winding into something short, i.e. when volume is a good predictor of importance. That is far less of a use case than people think. In the meantime, the result itself will — errors and all — suggest to readers that it is a true and reliable summary and we’re not going to doubt that, human as we are.</p>
</blockquote>

<h2 id="previously">Previously</h2>

<ul>
  <li>January 30, 2025: <a href="https://rolandtanglao.com/2025/01/30/p0814-a5ph-sketch-dev-llm-software-dev-david-crawshaw/">David Crawshaw’s sketch.dev LLM hello world gets into a loop about deleting duplicate files</a></li>
</ul>
:ET